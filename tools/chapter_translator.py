#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ –≥–ª–∞–≤ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –ø–∞–º—è—Ç—å
"""

import os
import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from config import get_api_key, TRANSLATION_MEMORY
from tools.context_manager import TranslationMemoryManager
from tools.consultation_base import DeepLConsultationBase
from tools.chapter_splitter import ChapterSplitter, TextSegment
from tools.deepl_cache import CachedDeepLTranslator
from tools.error_handler import ErrorHandler, ErrorCategory, ErrorSeverity, handle_errors
from tools.character_detector import CharacterDetector, CharacterType
from tools.performance_optimizer import PerformanceOptimizer, optimize_performance

@dataclass
class TranslationContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    chapter_number: str
    previous_chapters: List[str]
    main_characters: List[str]
    current_scene: str
    emotional_tone: str
    translation_style: str = "modern_web_novel"

@dataclass
class TranslationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞"""
    original_text: str
    translated_text: str
    translator: str
    confidence: float
    context_used: bool
    memory_hit: bool
    quality_score: float
    timestamp: str

class ChapterTranslator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ –≥–ª–∞–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø–∞–º—è—Ç—å—é"""
    
    def __init__(self):
        self.memory_manager = TranslationMemoryManager()
        self.deepl_consultant = DeepLConsultationBase()
        self.splitter = ChapterSplitter()
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π DeepL –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
        self.cached_translator = CachedDeepLTranslator()
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
        self.error_handler = ErrorHandler()
        
        # –î–µ—Ç–µ–∫—Ç–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        self.character_detector = CharacterDetector()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_optimizer = PerformanceOptimizer()
        
        # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self.translation_cache = {}
        
    @optimize_performance("translate_with_context")
    def translate_with_context(self, text: str, context: TranslationContext) -> List[TranslationResult]:
        """–ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        print(f"üîÑ –ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {context.chapter_number} —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º...")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        segments = self.splitter.split_by_lines(text)
        results = []
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        if len(segments) > 10:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            results = self._translate_segments_batch(segments, context)
        else:
            # –î–ª—è –º–∞–ª—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
            for segment in segments:
                result = self._translate_segment(segment, context)
                results.append(result)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                self._save_to_memory(segment, result, context)
        
        return results
    
    def _translate_segments_batch(self, segments: List[TextSegment], context: TranslationContext) -> List[TranslationResult]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        results = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Ç–∏–ø–∞–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        dialogue_segments = [s for s in segments if s.is_dialogue]
        system_segments = [s for s in segments if s.is_system]
        other_segments = [s for s in segments if not s.is_dialogue and not s.is_system]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
        for segment_group, group_name in [(dialogue_segments, "dialogue"), 
                                        (system_segments, "system"), 
                                        (other_segments, "other")]:
            if segment_group:
                print(f"üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(segment_group)} {group_name} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
                
                for segment in segment_group:
                    result = self._translate_segment(segment, context)
                    results.append(result)
                    self._save_to_memory(segment, result, context)
        
        return results
    
    def _translate_segment(self, segment: TextSegment, context: TranslationContext) -> TranslationResult:
        """–ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç"""
        
        # –ï—Å–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if segment.segment_type == 'empty_line' or not segment.content.strip():
            return TranslationResult(
                original_text=segment.content,
                translated_text='',
                translator="Empty_Line",
                confidence=1.0,
                context_used=False,
                memory_hit=False,  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –ø–∞–º—è—Ç—å
                quality_score=100.0,
                timestamp=datetime.now().isoformat()
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = f"{segment.content}_{context.translation_style}"
        if cache_key in self.translation_cache:
            cached_result = self.translation_cache[cache_key]
            return TranslationResult(
                original_text=segment.content,
                translated_text=cached_result['translated_text'],
                translator="Cache",
                confidence=0.9,
                context_used=True,
                memory_hit=True,
                quality_score=cached_result['quality_score'],
                timestamp=datetime.now().isoformat()
            )
        
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≥–æ—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Ñ—Ä–∞–∑—ã –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π –±–∞–∑–µ
        phrase_translation = self.memory_manager.get_phrase_translation(
            segment.content, 
            context.chapter_number
        )
        
        if phrase_translation:
            return TranslationResult(
                original_text=segment.content,
                translated_text=phrase_translation,
                translator="Reference_Base",
                confidence=1.0,
                context_used=True,
                memory_hit=True,
                quality_score=98.0,
                timestamp=datetime.now().isoformat()
            )
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ –ø–∞–º—è—Ç–∏
        similar_translations = self.memory_manager.find_similar(
            segment.content, 
            threshold=TRANSLATION_MEMORY["similarity_threshold"]
        )
        
        if similar_translations:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ö–æ–∂–∏–π –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∫ –æ—Å–Ω–æ–≤—É
            best_match = similar_translations[0]
            base_translation = best_match['target_text']
        else:
            # –ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ DeepL
            base_translation = self.cached_translator.translate_text(segment.content)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
        base_translation = self._apply_glossary(base_translation)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
        base_translation = self._check_forbidden_words(base_translation)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        character_type, confidence = self.character_detector.detect_character_from_text(segment.content)
        if character_type != CharacterType.UNKNOWN:
            base_translation = self._apply_character_style(base_translation, character_type.value)
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        adapted_translation = self._adapt_translation(
            base_translation, segment, context
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–µ—Ä–µ–≤–æ–¥–∞
        if similar_translations:
            translator = "Memory+Adaptation"
            confidence = similar_translations[0].get('similarity', 0.8)
            memory_hit = True
        else:
            translator = "DeepL+Adaptation"
            confidence = 0.8
            memory_hit = False
        
        result = TranslationResult(
            original_text=segment.content,
            translated_text=adapted_translation,
            translator=translator,
            confidence=confidence,
            context_used=True,
            memory_hit=memory_hit,
            quality_score=self._calculate_quality_score(adapted_translation),
            timestamp=datetime.now().isoformat()
        )
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self.translation_cache[cache_key] = {
            'translated_text': result.translated_text,
            'quality_score': result.quality_score
        }
        
        return result
    
    def _adapt_translation(self, base_translation: str, segment: TextSegment, 
                          context: TranslationContext) -> str:
        """–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–¥ —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        adapted = base_translation
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        if segment.character:
            adapted = self._adapt_for_character(adapted, segment.character, context)
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —Å—Ü–µ–Ω—É
        if context.current_scene:
            adapted = self._adapt_for_scene(adapted, context.current_scene)
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
        if context.emotional_tone:
            adapted = self._adapt_for_tone(adapted, context.emotional_tone)
        
        return adapted
    
    def _adapt_for_character(self, text: str, character: str, context: TranslationContext) -> str:
        """–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–¥ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        char_type, confidence = self.character_detector.detect_character_from_text(text)
        
        if char_type != CharacterType.UNKNOWN and confidence > 0.5:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            avoid_words = self.character_detector.get_character_avoid_words(char_type)
            prefer_words = self.character_detector.get_character_prefer_words(char_type)
            
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in avoid_words:
                if word in text:
                    # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ —Å–ª–æ–≤–æ
                    replacement = self._find_replacement(word, prefer_words)
                    text = text.replace(word, replacement)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ —Å–ª–æ–≤–∞ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
            for word in prefer_words:
                if word not in text and self._should_apply_word(word, text):
                    # –õ–æ–≥–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã—Ö —Å–ª–æ–≤
                    pass
        
        return text
    
    def _find_replacement(self, word: str, prefer_words: List[str]) -> str:
        """–ù–∞–π—Ç–∏ –∑–∞–º–µ–Ω—É –¥–ª—è –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∑–∞–º–µ–Ω—ã - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        replacements = {
            "—Å–µ–π": "—ç—Ç–æ—Ç",
            "–¥–∞–±—ã": "—á—Ç–æ–±—ã", 
            "–∏–±–æ": "–ø–æ—Ç–æ–º—É —á—Ç–æ",
            "–≤–µ—Å—å–º–∞": "–æ—á–µ–Ω—å",
            "–æ—Ç–Ω—é–¥—å": "—Å–æ–≤—Å–µ–º –Ω–µ"
        }
        
        return replacements.get(word, word)
    
    def _should_apply_word(self, word: str, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å—Ç–æ–∏—Ç –ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–æ–µ —Å–ª–æ–≤–æ"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        return len(text) > 20 and word not in text
    
    def _adapt_for_scene(self, text: str, scene: str) -> str:
        """–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–¥ —Å—Ü–µ–Ω—É"""
        # –ü—Ä–æ—Å—Ç–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        scene_adaptations = {
            "–±–æ–µ–≤–∞—è": {
                "–∑–∞–º–µ–¥–ª–µ–Ω–Ω–æ": "–º–µ–¥–ª–µ–Ω–Ω–æ",
                "–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ": "–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ"
            },
            "—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è": {
                "–≥—Ä—É–±–æ": "–Ω–µ–∂–Ω–æ",
                "—Ä–µ–∑–∫–æ": "–º—è–≥–∫–æ"
            }
        }
        
        if scene in scene_adaptations:
            adaptations = scene_adaptations[scene]
            for old, new in adaptations.items():
                text = text.replace(old, new)
        
        return text
    
    def _adapt_for_tone(self, text: str, tone: str) -> str:
        """–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–¥ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω"""
        tone_adaptations = {
            "–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π": {
                "—Å–ø–æ–∫–æ–π–Ω–æ": "–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ",
                "–º–µ–¥–ª–µ–Ω–Ω–æ": "–±—ã—Å—Ç—Ä–æ"
            },
            "–≥—Ä—É—Å—Ç–Ω—ã–π": {
                "—Ä–∞–¥–æ—Å—Ç–Ω–æ": "–≥—Ä—É—Å—Ç–Ω–æ",
                "–≤–µ—Å–µ–ª–æ": "–ø–µ—á–∞–ª—å–Ω–æ"
            }
        }
        
        if tone in tone_adaptations:
            adaptations = tone_adaptations[tone]
            for old, new in adaptations.items():
                text = text.replace(old, new)
        
        return text
    
    def _calculate_quality_score(self, text: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        score = 80.0  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        if len(text) < 10:
            score -= 20
        elif len(text) > 500:
            score -= 10
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∞—Ä—Ö–∞–∏–∑–º—ã
        archaisms = ["—Å–µ–π", "–¥–∞–±—ã", "–∏–±–æ", "–≤–µ—Å—å–º–∞", "–æ—Ç–Ω—é–¥—å"]
        for archaism in archaisms:
            if archaism in text.lower():
                score -= 5
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å
        natural_patterns = ["–î–∞–π –º–Ω–µ", "–ú–æ–∂–µ—à—å", "–•–æ—á—É", "–ü–æ—Ö–æ–∂–µ"]
        for pattern in natural_patterns:
            if pattern in text:
                score += 2
        
        return max(0, min(100, score))
    
    def _save_to_memory(self, segment: TextSegment, result: TranslationResult, 
                       context: TranslationContext):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –≤ –ø–∞–º—è—Ç—å"""
        try:
            from tools.context_manager import TranslationMemory
            
            memory = TranslationMemory(
                source_text=segment.content,
                target_text=result.translated_text,
                chapter=context.chapter_number,
                character=segment.character,
                context=context.current_scene,
                quality_score=result.quality_score
            )
            
            self.memory_manager.add_translation(memory)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å: {e}")
    
    def _apply_glossary(self, text: str) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π –∫ –ø–µ—Ä–µ–≤–æ–¥—É"""
        if not self.memory_manager.reference_data or 'glossary_terms' not in self.memory_manager.reference_data:
            return text
        
        glossary = self.memory_manager.reference_data['glossary_terms']
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏—è
        for category, terms in glossary.items():
            for english_term, russian_term in terms.items():
                # –ó–∞–º–µ–Ω—è–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–µ
                text = text.replace(english_term, russian_term)
        
        return text
    
    def _check_forbidden_words(self, text: str) -> str:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞"""
        forbidden_words = self.memory_manager.get_forbidden_words()
        
        if not forbidden_words:
            return text
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        alternatives = {}
        if (self.memory_manager.reference_data and 
            'translation_errors' in self.memory_manager.reference_data and
            'preferred_alternatives' in self.memory_manager.reference_data['translation_errors']):
            alternatives = self.memory_manager.reference_data['translation_errors']['preferred_alternatives']
        
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
        for forbidden_word in forbidden_words:
            if forbidden_word in text:
                if forbidden_word in alternatives:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
                    alternative = alternatives[forbidden_word].split(',')[0].strip()
                    text = text.replace(forbidden_word, alternative)
                    print(f"‚ö†Ô∏è –ó–∞–º–µ–Ω–µ–Ω–æ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ '{forbidden_word}' –Ω–∞ '{alternative}'")
                else:
                    print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ: '{forbidden_word}'")
        
        return text
    
    def _apply_character_style(self, text: str, character: str) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å—Ç–∏–ª—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        character_style = self.memory_manager.get_character_style(character)
        
        if not character_style or 'examples' not in character_style:
            return text
        
        examples = character_style['examples']
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ–Ω—ã
        for english_word, russian_style in examples.items():
            if english_word.lower() in text.lower():
                text = text.replace(english_word, russian_style)
        
        return text
    
    def _validate_structure(self, original_text: str, translated_text: str) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        original_lines = original_text.split('\n')
        translated_lines = translated_text.split('\n')
        
        validation = {
            'structure_match': len(original_lines) == len(translated_lines),
            'original_lines': len(original_lines),
            'translated_lines': len(translated_lines),
            'empty_lines_match': True,
            'issues': []
        }
        
        if not validation['structure_match']:
            validation['issues'].append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {len(original_lines)} ‚Üí {len(translated_lines)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        for i, (orig_line, trans_line) in enumerate(zip(original_lines, translated_lines)):
            orig_empty = not orig_line.strip()
            trans_empty = not trans_line.strip()
            
            if orig_empty != trans_empty:
                validation['empty_lines_match'] = False
                validation['issues'].append(f"–°—Ç—Ä–æ–∫–∞ {i+1}: –ø—É—Å—Ç–∞—è –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ ({orig_empty}) != –ø—É—Å—Ç–∞—è –≤ –ø–µ—Ä–µ–≤–æ–¥–µ ({trans_empty})")
        
        return validation
    
    def translate_file(self, file_path: str, context: TranslationContext) -> Dict[str, Any]:
        """–ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            results = self.translate_with_context(text, context)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
            translated_text = '\n'.join([r.translated_text for r in results])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            structure_validation = self._validate_structure(text, translated_text)
            
            if not structure_validation['structure_match']:
                print(f"‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç!")
                for issue in structure_validation['issues']:
                    print(f"   ‚Ä¢ {issue}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_segments = len(results)
            memory_hits = sum(1 for r in results if r.memory_hit)
            avg_quality = sum(r.quality_score for r in results) / total_segments if total_segments > 0 else 0
            
            return {
                'original_text': text,
                'translated_text': translated_text,
                'results': results,
                'structure_validation': structure_validation,
                'statistics': {
                    'total_segments': total_segments,
                    'memory_hits': memory_hits,
                    'memory_hit_rate': memory_hits / total_segments if total_segments > 0 else 0,
                    'average_quality': avg_quality,
                    'translators_used': list(set(r.translator for r in results))
                },
                'context': context,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Ñ–∞–π–ª–∞: {e}")
            return {'error': str(e)}

def test_chapter_translator():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ –≥–ª–∞–≤"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ï–†–ï–í–û–î–ß–ò–ö–ê –ì–õ–ê–í")
    print("=" * 50)
    
    translator = ChapterTranslator()
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context = TranslationContext(
        chapter_number="–¢–µ—Å—Ç",
        previous_chapters=["–ì–ª–∞–≤–∞ 1"],
        main_characters=["–¶–∑—è–Ω –ß—ç–Ω—å", "–ï –¶–∏–Ω—á—ç–Ω"],
        current_scene="–î–∏–∞–ª–æ–≥ –≤ –≥–æ—Ä–∞—Ö",
        emotional_tone="–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π"
    )
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    test_text = """"Finally, she's gone!" Jiang Chen exhaled with relief.

From his perspective, apart from being brainless, Ye Qingcheng was like bad luck - better to stay as far away from her as possible.

"System, would it count as interfering with slacking off if I take action?" Jiang Chen inquired."""
    
    # –¢–µ—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞
    results = translator.translate_with_context(test_text, context)
    
    print(f"üìù –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(results)}")
    
    for i, result in enumerate(results, 1):
        print(f"\n{i}. –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫: {result.translator}")
        print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.1f}/100")
        print(f"   –ü–∞–º—è—Ç—å: {'–î–∞' if result.memory_hit else '–ù–µ—Ç'}")
        print(f"   –¢–µ–∫—Å—Ç: {result.translated_text[:100]}...")
    
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    test_chapter_translator()
