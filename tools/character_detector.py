#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–µ—Ç–µ–∫—Ç–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∏–ª—è —Ä–µ—á–∏ –∏ –º—ã—Å–ª–µ–π
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂ –≥–æ–≤–æ—Ä–∏—Ç –∏–ª–∏ –¥—É–º–∞–µ—Ç
"""

import re
import json
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

class CharacterType(Enum):
    """–¢–∏–ø—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
    JIANG_CHEN = "Jiang_Chen"
    YE_QINGCHENG = "Ye_Qingcheng"
    DU_GUYUN = "Du_Guyun"
    ELDER = "Elder"
    SYSTEM = "System"
    NARRATOR = "Narrator"
    UNKNOWN = "Unknown"

@dataclass
class CharacterProfile:
    """–ü—Ä–æ—Ñ–∏–ª—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
    name: str
    character_type: CharacterType
    speech_patterns: List[str]
    thought_patterns: List[str]
    keywords: List[str]
    style_preferences: Dict[str, Any]
    avoid_words: List[str]
    prefer_words: List[str]

class CharacterDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self, profiles_file: str = "character_voices.json"):
        self.profiles_file = profiles_file
        self.character_profiles = self._load_character_profiles()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        self.name_patterns = {
            "–¶–∑—è–Ω –ß—ç–Ω—å": CharacterType.JIANG_CHEN,
            "Jiang Chen": CharacterType.JIANG_CHEN,
            "—Ü–∑—è–Ω —á—ç–Ω—å": CharacterType.JIANG_CHEN,
            "jiang chen": CharacterType.JIANG_CHEN,
            
            "–ï –¶–∏–Ω—á—ç–Ω": CharacterType.YE_QINGCHENG,
            "Ye Qingcheng": CharacterType.YE_QINGCHENG,
            "–µ —Ü–∏–Ω—á—ç–Ω": CharacterType.YE_QINGCHENG,
            "ye qingcheng": CharacterType.YE_QINGCHENG,
            
            "–î—É –ì—É—é–Ω—å": CharacterType.DU_GUYUN,
            "Du Guyun": CharacterType.DU_GUYUN,
            "–¥—É –≥—É—é–Ω—å": CharacterType.DU_GUYUN,
            "du guyun": CharacterType.DU_GUYUN,
            
            "–°—Ç–∞—Ä–µ–π—à–∏–Ω–∞": CharacterType.ELDER,
            "Elder": CharacterType.ELDER,
            "—Å—Ç–∞—Ä–µ–π—à–∏–Ω–∞": CharacterType.ELDER,
            "elder": CharacterType.ELDER,
        }
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self.system_patterns = [
            r"–î–∏–Ω—å!.*",
            r"–°–∏—Å—Ç–µ–º–∞.*",
            r"–û–ø–æ–≤–µ—â–µ–Ω–∏–µ.*",
            r"–ü–æ–ª—É—á–µ–Ω–æ.*",
            r"–ù–∞–≥—Ä–∞–¥–∞.*",
            r"System.*",
            r"Notification.*"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∏–∞–ª–æ–≥–æ–≤
        self.dialogue_patterns = [
            r'"[^"]*"',  # –û–±—ã—á–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            r'¬´[^¬ª]*¬ª',  # –Å–ª–æ—á–∫–∏
            r'‚Äî[^‚Äî]*‚Äî',  # –¢–∏—Ä–µ
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –º—ã—Å–ª–µ–π
        self.thought_patterns = [
            r'\[[^\]]*\]',  # –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏
            r'\([^)]*\)',   # –ö—Ä—É–≥–ª—ã–µ —Å–∫–æ–±–∫–∏
        ]
    
    def _load_character_profiles(self) -> Dict[CharacterType, CharacterProfile]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        try:
            with open(self.profiles_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            profiles = {}
            for char_type, profile_data in data.items():
                if char_type in [e.value for e in CharacterType]:
                    char_enum = CharacterType(char_type)
                    profiles[char_enum] = CharacterProfile(
                        name=profile_data.get("name", char_type),
                        character_type=char_enum,
                        speech_patterns=profile_data.get("speech_patterns", []),
                        thought_patterns=profile_data.get("thought_patterns", []),
                        keywords=profile_data.get("keywords", []),
                        style_preferences=profile_data.get("style_preferences", {}),
                        avoid_words=profile_data.get("avoid", []),
                        prefer_words=profile_data.get("prefer", [])
                    )
            
            return profiles
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {e}")
            return self._create_default_profiles()
    
    def _create_default_profiles(self) -> Dict[CharacterType, CharacterProfile]:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            CharacterType.JIANG_CHEN: CharacterProfile(
                name="–¶–∑—è–Ω –ß—ç–Ω—å",
                character_type=CharacterType.JIANG_CHEN,
                speech_patterns=["–î–∞–π –º–Ω–µ", "–ú–æ–∂–µ—à—å", "–•–æ—á—É"],
                thought_patterns=["–°–µ—Ä—å—ë–∑–Ω–æ?", "–ë–ª–∏–Ω", "–î–∞ –Ω—É –Ω–∞—Ñ–∏–≥"],
                keywords=["–±–µ–∑–¥–µ–ª—å–µ", "—Å–∏—Å—Ç–µ–º–∞", "–Ω–∞–≥—Ä–∞–¥–∞"],
                style_preferences={"style": "modern_casual"},
                avoid_words=["—Å–µ–π", "–¥–∞–±—ã", "–∏–±–æ", "–≤–µ—Å—å–º–∞"],
                prefer_words=["–∫—Ä—É—Ç–æ", "—Ä–µ–∞–ª—å–Ω–æ", "–º–æ—â–Ω—ã–π"]
            ),
            CharacterType.YE_QINGCHENG: CharacterProfile(
                name="–ï –¶–∏–Ω—á—ç–Ω",
                character_type=CharacterType.YE_QINGCHENG,
                speech_patterns=["–ü–æ–∑–≤–æ–ª—å—Ç–µ", "–ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã", "–Ø —Ö–æ—Ç–µ–ª–∞ –±—ã"],
                thought_patterns=["–ù–µ—É–∂–µ–ª–∏", "–î–æ–ª–∂–Ω–∞ –ª–∏ —è"],
                keywords=["—ç–ª–µ–≥–∞–Ω—Ç–Ω–æ—Å—Ç—å", "–∫—Ä–∞—Å–æ—Ç–∞", "–¥–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤–æ"],
                style_preferences={"style": "elegant_modern"},
                avoid_words=["—Å–µ–π", "–¥–∞–±—ã", "–∏–±–æ", "–≤–µ—Å—å–º–∞"],
                prefer_words=["–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ", "–æ—á–µ–Ω—å", "–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ"]
            ),
            CharacterType.SYSTEM: CharacterProfile(
                name="–°–∏—Å—Ç–µ–º–∞",
                character_type=CharacterType.SYSTEM,
                speech_patterns=["–î–∏–Ω—å!", "–ü–æ–ª—É—á–µ–Ω–æ", "–ù–∞–≥—Ä–∞–¥–∞"],
                thought_patterns=[],
                keywords=["—Å–∏—Å—Ç–µ–º–∞", "–Ω–∞–≥—Ä–∞–¥–∞", "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ"],
                style_preferences={"style": "game_like"},
                avoid_words=[],
                prefer_words=["–î–∏–Ω—å!", "–ù–∞–≥—Ä–∞–¥–∞ –ø–æ–ª—É—á–µ–Ω–∞!"]
            )
        }
    
    def detect_character_from_text(self, text: str) -> Tuple[CharacterType, float]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ —Ç–µ–∫—Å—Ç—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–º–µ–Ω
        for name, char_type in self.name_patterns.items():
            if name in text:
                return char_type, 1.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.system_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return CharacterType.SYSTEM, 0.9
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å —Ä–µ—á–∏
        style_analysis = self._analyze_speech_style(text)
        if style_analysis:
            return style_analysis
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keyword_analysis = self._analyze_keywords(text)
        if keyword_analysis:
            return keyword_analysis
        
        return CharacterType.UNKNOWN, 0.0
    
    def _analyze_speech_style(self, text: str) -> Optional[Tuple[CharacterType, float]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏–ª—å —Ä–µ—á–∏"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        best_match = None
        best_score = 0.0
        
        for char_type, profile in self.character_profiles.items():
            score = 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ —Å–ª–æ–≤–∞
            for word in profile.prefer_words:
                if word.lower() in text.lower():
                    score += 0.2
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–±–µ–≥–∞–µ–º—ã–µ —Å–ª–æ–≤–∞ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –±–∞–ª–ª)
            for word in profile.avoid_words:
                if word.lower() in text.lower():
                    score -= 0.1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ—á–∏
            for pattern in profile.speech_patterns:
                if pattern.lower() in text.lower():
                    score += 0.3
            
            if score > best_score:
                best_score = score
                best_match = char_type
        
        if best_match and best_score > 0.3:
            return best_match, best_score
        
        return None
    
    def _analyze_keywords(self, text: str) -> Optional[Tuple[CharacterType, float]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        text_lower = text.lower()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        keyword_scores = {}
        for char_type, profile in self.character_profiles.items():
            score = 0
            for keyword in profile.keywords:
                if keyword.lower() in text_lower:
                    score += 1
            keyword_scores[char_type] = score
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if keyword_scores:
            best_type = max(keyword_scores, key=keyword_scores.get)
            best_score = keyword_scores[best_type]
            
            if best_score > 0:
                confidence = min(0.8, best_score * 0.2)
                return best_type, confidence
        
        return None
    
    def detect_character_from_dialogue(self, dialogue: str) -> Tuple[CharacterType, float]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ –¥–∏–∞–ª–æ–≥—É"""
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        clean_dialogue = re.sub(r'["¬´¬ª‚Äî]', '', dialogue).strip()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å –¥–∏–∞–ª–æ–≥–∞
        return self.detect_character_from_text(clean_dialogue)
    
    def detect_character_from_thoughts(self, thoughts: str) -> Tuple[CharacterType, float]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ –º—ã—Å–ª—è–º"""
        # –£–±–∏—Ä–∞–µ–º —Å–∫–æ–±–∫–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        clean_thoughts = re.sub(r'[\[\]()]', '', thoughts).strip()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å –º—ã—Å–ª–µ–π
        return self.detect_character_from_text(clean_thoughts)
    
    def get_character_style_preferences(self, character_type: CharacterType) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —Å—Ç–∏–ª—è –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        if character_type in self.character_profiles:
            return self.character_profiles[character_type].style_preferences
        return {}
    
    def get_character_avoid_words(self, character_type: CharacterType) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–µ–¥—É–µ—Ç –∏–∑–±–µ–≥–∞—Ç—å –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        if character_type in self.character_profiles:
            return self.character_profiles[character_type].avoid_words
        return []
    
    def get_character_prefer_words(self, character_type: CharacterType) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        if character_type in self.character_profiles:
            return self.character_profiles[character_type].prefer_words
        return []
    
    def analyze_text_segments(self, text: str) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞"""
        segments = []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', text)
        
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–µ–≥–º–µ–Ω—Ç–∞
            segment_type = "description"
            if any(re.search(pattern, sentence) for pattern in self.dialogue_patterns):
                segment_type = "dialogue"
            elif any(re.search(pattern, sentence) for pattern in self.thought_patterns):
                segment_type = "thoughts"
            elif any(re.search(pattern, sentence, re.IGNORECASE) for pattern in self.system_patterns):
                segment_type = "system"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            character_type, confidence = self.detect_character_from_text(sentence)
            
            segments.append({
                "index": i,
                "text": sentence,
                "type": segment_type,
                "character": character_type.value,
                "confidence": confidence,
                "style_preferences": self.get_character_style_preferences(character_type),
                "avoid_words": self.get_character_avoid_words(character_type),
                "prefer_words": self.get_character_prefer_words(character_type)
            })
        
        return segments
    
    def get_character_statistics(self, text: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º –≤ —Ç–µ–∫—Å—Ç–µ"""
        segments = self.analyze_text_segments(text)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        character_counts = {}
        type_counts = {}
        
        for segment in segments:
            char = segment["character"]
            seg_type = segment["type"]
            
            character_counts[char] = character_counts.get(char, 0) + 1
            type_counts[seg_type] = type_counts.get(seg_type, 0) + 1
        
        return {
            "total_segments": len(segments),
            "character_distribution": character_counts,
            "type_distribution": type_counts,
            "segments": segments
        }
    
    def print_character_analysis(self, text: str):
        """–í—ã–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        stats = self.get_character_statistics(text)
        
        print("\nüé≠ –ê–ù–ê–õ–ò–ó –ü–ï–†–°–û–ù–ê–ñ–ï–ô")
        print("=" * 40)
        print(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {stats['total_segments']}")
        
        print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º:")
        for char, count in stats['character_distribution'].items():
            print(f"  ‚Ä¢ {char}: {count}")
        
        print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
        for seg_type, count in stats['type_distribution'].items():
            print(f"  ‚Ä¢ {seg_type}: {count}")
        
        print("\n–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:")
        for segment in stats['segments'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"  {segment['index']}. [{segment['type']}] {segment['character']} ({segment['confidence']:.2f})")
            print(f"     {segment['text'][:50]}...")

def test_character_detector():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –î–ï–¢–ï–ö–¢–û–†–ê –ü–ï–†–°–û–ù–ê–ñ–ï–ô")
    print("=" * 50)
    
    detector = CharacterDetector()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        "–¶–∑—è–Ω –ß—ç–Ω—å –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –≥–æ—Ä—É –∏ –ø–æ–¥—É–º–∞–ª: ¬´–î–∞ –ø–æ—à–ª–æ –æ–Ω–æ –≤—Å—ë!¬ª",
        "–ï –¶–∏–Ω—á—ç–Ω —ç–ª–µ–≥–∞–Ω—Ç–Ω–æ –ø–æ–∫–ª–æ–Ω–∏–ª–∞—Å—å: ¬´–ü–æ–∑–≤–æ–ª—å—Ç–µ –º–Ω–µ –≤—ã—Ä–∞–∑–∏—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å¬ª",
        "–î–∏–Ω—å! –ó–∞ —É—Å–ø–µ—à–Ω–æ–µ –±–µ–∑–¥–µ–ª—å–µ –ø–æ–ª—É—á–µ–Ω–æ: –ò–º–ø–µ—Ä–∞—Ç–æ—Ä—Å–∫–æ–µ –æ—Ä—É–∂–∏–µ!",
        "–°—Ç–∞—Ä–µ–π—à–∏–Ω–∞ –º—É–¥—Ä–æ –∫–∏–≤–Ω—É–ª: ¬´–ú–æ–ª–æ–¥–æ–π —á–µ–ª–æ–≤–µ–∫, –ø—É—Ç—å —Ç–≤–æ–π —Ç–µ—Ä–Ω–∏—Å—Ç¬ª",
        "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂ —á—Ç–æ-—Ç–æ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª"
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{i}. –¢–µ—Å—Ç: {text}")
        char_type, confidence = detector.detect_character_from_text(text)
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {char_type.value} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
    
    # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    full_text = "\n".join(test_texts)
    detector.print_character_analysis(full_text)
    
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    test_character_detector()
