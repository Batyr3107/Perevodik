#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–í–∞–ª–∏–¥–∞—Ç–æ—Ä –≥–ª–∞–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –∫–∞—á–µ—Å—Ç–≤–æ
"""

import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from config import QUALITY_METRICS, MIN_QUALITY_THRESHOLDS, BANNED_ARCHAISMS
from tools.chapter_splitter import ChapterSplitter, TextSegment

@dataclass
class ValidationIssue:
    """–ü—Ä–æ–±–ª–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    issue_type: str
    severity: str  # 'critical', 'high', 'medium', 'low'
    message: str
    line_number: int
    context: str
    suggestion: Optional[str] = None

@dataclass
class ValidationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    is_valid: bool
    issues: List[ValidationIssue]
    quality_scores: Dict[str, float]
    overall_score: float
    recommendations: List[str]

class ChapterValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –≥–ª–∞–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        self.splitter = ChapterSplitter()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        self.archaism_patterns = BANNED_ARCHAISMS
        self.calque_patterns = [
            "–∫—Ä–∞–π–Ω–µ", "—Å–ª–µ–≤–∞ –∏ —Å–ø—Ä–∞–≤–∞", "—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–∞", 
            "–ù–∞ –µ–≥–æ –≤–∑–≥–ª—è–¥", "—Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–ª", "–æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å",
            "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ", "–∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å —á—É–≤—Å—Ç–≤–æ"
        ]
        self.formal_dialogue_patterns = [
            "–Ø —Å–æ–±–∏—Ä–∞—é—Å—å", "–ü–æ–∑–≤–æ–ª—å—Ç–µ –º–Ω–µ", "–ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã",
            "–Ø —Ö–æ—Ç–µ–ª –±—ã", "–ö–∞–∂–µ—Ç—Å—è, —á—Ç–æ", "–Ø –±–æ—é—Å—å, —á—Ç–æ"
        ]
        
        # –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        self.glossary_terms = {
            "Slack-Off System": "–°–∏—Å—Ç–µ–º–∞ –ë–µ–∑–¥–µ–ª—å—è",
            "Holy Son": "–°–≤—è—Ç–æ–π –°—ã–Ω",
            "Banished Immortal Peak": "–ü–∏–∫ –ò–∑–≥–Ω–∞–Ω–Ω–æ–≥–æ –ë–µ—Å—Å–º–µ—Ä—Ç–Ω–æ–≥–æ",
            "Primordial Holy Land": "–ò–∑–Ω–∞—á–∞–ª—å–Ω–∞—è –°–≤—è—Ç–∞—è –ó–µ–º–ª—è",
            "dog licker": "–ø–æ–¥—Ö–∞–ª–∏–º"
        }
    
    def validate_chapter(self, original_text: str, translated_text: str, 
                        context: Optional[Dict] = None) -> ValidationResult:
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≥–ª–∞–≤—ã"""
        print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –≥–ª–∞–≤—ã...")
        
        issues = []
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        structure_issues = self._validate_structure(original_text, translated_text)
        issues.extend(structure_issues)
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∞–∏–∑–º–æ–≤
        archaism_issues = self._validate_archaisms(translated_text)
        issues.extend(archaism_issues)
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ª—å–∫–∏
        calque_issues = self._validate_calques(translated_text)
        issues.extend(calque_issues)
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤
        dialogue_issues = self._validate_dialogues(translated_text)
        issues.extend(dialogue_issues)
        
        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
        terminology_issues = self._validate_terminology(translated_text)
        issues.extend(terminology_issues)
        
        # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
        readability_issues = self._validate_readability(translated_text)
        issues.extend(readability_issues)
        
        # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        consistency_issues = self._validate_consistency(translated_text)
        issues.extend(consistency_issues)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_scores = self._calculate_quality_scores(translated_text, issues)
        overall_score = self._calculate_overall_score(quality_scores)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = self._generate_recommendations(issues, quality_scores)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        critical_issues = [i for i in issues if i.severity == 'critical']
        is_valid = len(critical_issues) == 0 and overall_score >= 70
        
        return ValidationResult(
            is_valid=is_valid,
            issues=issues,
            quality_scores=quality_scores,
            overall_score=overall_score,
            recommendations=recommendations
        )
    
    def _validate_structure(self, original: str, translated: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        orig_lines = len([l for l in original.split('\n') if l.strip()])
        trans_lines = len([l for l in translated.split('\n') if l.strip()])
        
        if abs(orig_lines - trans_lines) > 2:
            issues.append(ValidationIssue(
                issue_type="–°—Ç—Ä—É–∫—Ç—É—Ä–∞",
                severity="high",
                message=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç: {trans_lines} vs {orig_lines}",
                line_number=0,
                context="–û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
                suggestion="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –∞–±–∑–∞—Ü—ã"
            ))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        orig_empty = original.count('\n\n')
        trans_empty = translated.count('\n\n')
        
        if abs(orig_empty - trans_empty) > 1:
            issues.append(ValidationIssue(
                issue_type="–°—Ç—Ä—É–∫—Ç—É—Ä–∞",
                severity="medium",
                message=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç: {trans_empty} vs {orig_empty}",
                line_number=0,
                context="–ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏",
                suggestion="–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏"
            ))
        
        return issues
    
    def _validate_archaisms(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞—Ä—Ö–∞–∏–∑–º—ã"""
        issues = []
        
        for archaism in self.archaism_patterns:
            if archaism in text.lower():
                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
                for match in re.finditer(re.escape(archaism), text, re.IGNORECASE):
                    line_number = text[:match.start()].count('\n') + 1
                    context = text[max(0, match.start()-30):match.end()+30]
                    
                    issues.append(ValidationIssue(
                        issue_type="–ê—Ä—Ö–∞–∏–∑–º",
                        severity="critical",
                        message=f"–ù–∞–π–¥–µ–Ω –∞—Ä—Ö–∞–∏–∑–º: '{archaism}'",
                        line_number=line_number,
                        context=context,
                        suggestion=f"–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–æ–≥"
                    ))
        
        return issues
    
    def _validate_calques(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ª—å–∫–∏"""
        issues = []
        
        for calque in self.calque_patterns:
            if calque in text:
                for match in re.finditer(re.escape(calque), text):
                    line_number = text[:match.start()].count('\n') + 1
                    context = text[max(0, match.start()-30):match.end()+30]
                    
                    issues.append(ValidationIssue(
                        issue_type="–ö–∞–ª—å–∫–∞",
                        severity="high",
                        message=f"–ù–∞–π–¥–µ–Ω–∞ –∫–∞–ª—å–∫–∞: '{calque}'",
                        line_number=line_number,
                        context=context,
                        suggestion="–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ"
                    ))
        
        return issues
    
    def _validate_dialogues(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤"""
        issues = []
        
        for pattern in self.formal_dialogue_patterns:
            if pattern in text:
                for match in re.finditer(re.escape(pattern), text):
                    line_number = text[:match.start()].count('\n') + 1
                    context = text[max(0, match.start()-30):match.end()+30]
                    
                    issues.append(ValidationIssue(
                        issue_type="–§–æ—Ä–º–∞–ª—å–Ω—ã–π –¥–∏–∞–ª–æ–≥",
                        severity="medium",
                        message=f"–§–æ—Ä–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: '{pattern}'",
                        line_number=line_number,
                        context=context,
                        suggestion="–£–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"
                    ))
        
        return issues
    
    def _validate_terminology(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏"""
        issues = []
        
        for en_term, ru_term in self.glossary_terms.items():
            if en_term in text and ru_term not in text:
                issues.append(ValidationIssue(
                    issue_type="–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è",
                    severity="high",
                    message=f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ—Ä–º–∏–Ω: '{en_term}' –≤–º–µ—Å—Ç–æ '{ru_term}'",
                    line_number=0,
                    context="–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è",
                    suggestion=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å '{ru_term}'"
                ))
        
        return issues
    
    def _validate_readability(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏"""
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        sentences = re.split(r'[.!?]+', text)
        long_sentences = []
        
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if sentence:
                words = sentence.split()
                if len(words) > 15:  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    line_number = text.find(sentence) // 50 + 1  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ
                    long_sentences.append((i+1, len(words), sentence[:50]))
        
        if long_sentences:
            for line_num, word_count, context in long_sentences:
                issues.append(ValidationIssue(
                    issue_type="–ß–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å",
                    severity="medium",
                    message=f"–î–ª–∏–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {word_count} —Å–ª–æ–≤",
                    line_number=line_num,
                    context=context,
                    suggestion="–†–∞–∑–±–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"
                ))
        
        return issues
    
    def _validate_consistency(self, text: str) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏"""
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏–º–µ–Ω –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        character_names = {
            "–¶–∑—è–Ω –ß—ç–Ω—å": ["Jiang Chen", "—Ü–∑—è–Ω —á—ç–Ω—å"],
            "–ï –¶–∏–Ω—á—ç–Ω": ["Ye Qingcheng", "–µ —Ü–∏–Ω—á—ç–Ω"],
            "–î—É –ì—É—é–Ω—å": ["Du Guyun", "–¥—É –≥—É—é–Ω—å"]
        }
        
        for correct_name, variants in character_names.items():
            found_variants = []
            for variant in variants:
                if variant in text:
                    found_variants.append(variant)
            
            if len(found_variants) > 1:
                issues.append(ValidationIssue(
                    issue_type="–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å",
                    severity="high",
                    message=f"–ù–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–º–µ–Ω: {', '.join(found_variants)}",
                    line_number=0,
                    context="–ò–º–µ–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π",
                    suggestion=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ '{correct_name}'"
                ))
        
        return issues
    
    def _calculate_quality_scores(self, text: str, issues: List[ValidationIssue]) -> Dict[str, float]:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º"""
        scores = {}
        
        # –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤ (30%)
        dialogue_issues = [i for i in issues if i.issue_type == "–§–æ—Ä–º–∞–ª—å–Ω—ã–π –¥–∏–∞–ª–æ–≥"]
        dialogue_score = max(0, 100 - len(dialogue_issues) * 10)
        scores["dialogue_naturalness"] = dialogue_score
        
        # –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ—Ä–º–∏–Ω–æ–≤ (25%)
        term_issues = [i for i in issues if i.issue_type == "–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è"]
        term_score = max(0, 100 - len(term_issues) * 15)
        scores["terminology_consistency"] = term_score
        
        # –ì–æ–ª–æ—Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (25%) - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        archaism_issues = [i for i in issues if i.issue_type == "–ê—Ä—Ö–∞–∏–∑–º"]
        voice_score = max(0, 100 - len(archaism_issues) * 20)
        scores["character_voice"] = voice_score
        
        # –ö—É–ª—å—Ç—É—Ä–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è (20%)
        calque_issues = [i for i in issues if i.issue_type == "–ö–∞–ª—å–∫–∞"]
        cultural_score = max(0, 100 - len(calque_issues) * 15)
        scores["cultural_adaptation"] = cultural_score
        
        return scores
    
    def _calculate_overall_score(self, quality_scores: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞"""
        total_score = 0
        for metric, weight in QUALITY_METRICS.items():
            if metric in quality_scores:
                total_score += quality_scores[metric] * weight
        return round(total_score, 1)
    
    def _generate_recommendations(self, issues: List[ValidationIssue], 
                                 quality_scores: Dict[str, float]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–æ–±–ª–µ–º–∞–º
        critical_issues = [i for i in issues if i.severity == "critical"]
        if critical_issues:
            recommendations.append(f"üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: {len(critical_issues)} - —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        for metric, score in quality_scores.items():
            threshold = MIN_QUALITY_THRESHOLDS.get(metric, 0)
            if score < threshold:
                recommendations.append(f"‚ö†Ô∏è {metric}: {score:.1f}/{threshold} - –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if quality_scores.get("dialogue_naturalness", 0) < 80:
            recommendations.append("üí¨ –£–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–∏–∞–ª–æ–≥–∏ - —É–±—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å")
        
        if quality_scores.get("terminology_consistency", 0) < 90:
            recommendations.append("üìö –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –ø–æ –≥–ª–æ—Å—Å–∞—Ä–∏—é")
        
        if quality_scores.get("cultural_adaptation", 0) < 75:
            recommendations.append("üåç –£–±—Ä–∞—Ç—å –∫–∞–ª—å–∫–∏ - –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ —Ä—É—Å—Å–∫–∏–π")
        
        return recommendations
    
    def print_validation_report(self, result: ValidationResult):
        """–í—ã–≤–µ—Å—Ç–∏ –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        print("\n" + "="*60)
        print("üìã –û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò")
        print("="*60)
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        status_color = "üü¢" if result.is_valid else "üî¥"
        print(f"{status_color} –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {result.overall_score:.1f}/100")
        print(f"üìä –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {'‚úÖ –í–∞–ª–∏–¥–Ω–æ' if result.is_valid else '‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω–æ'}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        print(f"\nüìà –î–ï–¢–ê–õ–¨–ù–´–ï –û–¶–ï–ù–ö–ò:")
        for metric, score in result.quality_scores.items():
            threshold = MIN_QUALITY_THRESHOLDS.get(metric, 0)
            status = "‚úÖ" if score >= threshold else "‚ùå"
            print(f"   {status} {metric}: {score:.1f}/{threshold}")
        
        # –ü—Ä–æ–±–ª–µ–º—ã –ø–æ —Ç–∏–ø–∞–º
        if result.issues:
            print(f"\nüîç –ü–†–û–ë–õ–ï–ú–´ –ü–û –¢–ò–ü–ê–ú:")
            issue_groups = {}
            for issue in result.issues:
                if issue.issue_type not in issue_groups:
                    issue_groups[issue.issue_type] = []
                issue_groups[issue.issue_type].append(issue)
            
            for issue_type, issues in issue_groups.items():
                critical = len([i for i in issues if i.severity == "critical"])
                high = len([i for i in issues if i.severity == "high"])
                medium = len([i for i in issues if i.severity == "medium"])
                print(f"   ‚Ä¢ {issue_type}: {len(issues)} (üî¥{critical} üü†{high} üü°{medium})")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if result.recommendations:
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in result.recommendations:
                print(f"   {rec}")
        
        print("="*60)

def test_chapter_validator():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –≥–ª–∞–≤"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–ê–õ–ò–î–ê–¢–û–†–ê –ì–õ–ê–í")
    print("=" * 50)
    
    validator = ChapterValidator()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    original_text = """Chapter 1: Test

"Hello!" said the character.

This is a test chapter with some content."""
    
    translated_text = """–ì–ª–∞–≤–∞ 1: –¢–µ—Å—Ç

"–ü—Ä–∏–≤–µ—Ç!" —Å–∫–∞–∑–∞–ª –ø–µ—Ä—Å–æ–Ω–∞–∂.

–°–µ–π —Ç–µ—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–µ—Å—å–º–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç."""
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    result = validator.validate_chapter(original_text, translated_text)
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    validator.print_validation_report(result)
    
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    test_chapter_validator()
